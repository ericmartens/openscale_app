{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watson OpenScale Mortgage Default Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook should be run in a [Watson Studio](https://dataplatform.ibm.com/) project with Python 3.6 or greater. It requires a free lite version of [Watson Machine Learning](https://cloud.ibm.com/catalog/services/machine-learning).\n",
    "\n",
    "This notebook will train, save and deploy a machine learning model to predict mortgage defaults. Then, it will configure OpenScale to monitor the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provision services and create credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need credentials for Watson Machine Learning. If you already have a WML instance, you may use credentials for it. To provision a new Lite instance of WML, use the [Cloud catalog](https://cloud.ibm.com/catalog/services/machine-learning), give your service a name, and click **Create**. Once your instance is created, click the **Service Credentials** link on the left side of the screen. Click the **New credential** button, give your credentials a name, and click **Add**. Your new credentials can be accessed by clicking the **View credentials** button. Copy and paste your WML credentials into the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WML_CREDENTIALS = {\n",
    "    \"apikey\": \"key\",\n",
    "    \"iam_apikey_description\": \"description\",\n",
    "    \"iam_apikey_name\": \"auto-generated-apikey\",\n",
    "    \"iam_role_crn\": \"crn:v1:bluemix:public:iam::::serviceRole:Writer\",\n",
    "    \"iam_serviceid_crn\": \"crn:v1:bluemix:public:iam-identity::\",\n",
    "    \"instance_id\": \"instance_id\",\n",
    "    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can generate a Cloud API key [here](https://cloud.ibm.com/iam/apikeys)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLOUD_API_KEY = \"xxxxxxxxxxxxxxxxx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have already set up an OpenScale datamart, or if you would like to use the free internal PostgreSQL datamart, you can skip the following cell. If you are setting up a new instance of OpenScale and would like to use a paid database service, paste your [Db2](https://cloud.ibm.com/catalog/services/db2-warehouse) or [PostgreSQL](https://cloud.ibm.com/catalog/services/databases-for-postgresql) credentials below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_CREDENTIALS = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may give your model and deployment a custom name below; however, if you change the values below, be sure to use the same names in all subsequent notebooks in this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'Mortgage Default'\n",
    "DEPLOYMENT_NAME = 'Mortgage Default - Production'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade ibm-ai-openscale --no-cache | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you can run all cells in this notebook using the menus above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the scikit-learn framework and check the version. This notebook was developed using sklearn version 0.20.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the provided credentials above to create a new Watson Machine Learning client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient\n",
    "\n",
    "wml_client = WatsonMachineLearningAPIClient(WML_CREDENTIALS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all models for this instance of Watson Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wml_client.repository.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the pandas library, download and examine our training data. The data contains an 'ID' field for the loan ID, which will not be used in training the model and is dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/emartensibm/openscale-demos/master/mortgage-default/data/Mortgage_Full_Records.csv'\n",
    "df_raw = pd.read_csv(url)\n",
    "df = df_raw.drop('ID', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the sklearn libraries we need, including encoders, transformers, scalers, and our random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the categorical features, and create a one-hot encoder pipeline for them.\n",
    "\n",
    "Next, identify the numerical features and use the min-max scaler to scale the values, which will significantly increase our model's accuracy.\n",
    "\n",
    "Finally, organize the categorical encoder and the scaler into a pipeline so the deployed model can work with our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['AppliedOnline','Residence','Location']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "scaled_features = ['Income','Yrs_at_Current_Address','Yrs_with_Current_Employer',\\\n",
    "                   'Number_of_Cards','Creditcard_Debt','Loan_Amount','SalePrice']\n",
    "scale_transformer = Pipeline(steps=[('scale', MinMaxScaler())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "        ('scaler', scale_transformer, scaled_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the train/test split, train the model, and score the model quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('MortgageDefault', axis=1)\n",
    "y = df['MortgageDefault']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\n",
    "\n",
    "model = clf.fit(X_train, y_train)\n",
    "res_predict = model.predict(X_test)\n",
    "print(\"model score: %.3f\" % clf.score(X_test, y_test))\n",
    "print(classification_report(y_test, res_predict, target_names=[\"False\", \"True\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model to Watson Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the list of models in the WML instance, and remove pre-existing versions of this model. This allows the notebook to be re-run to reset all data if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_deployment_ids = wml_client.deployments.get_uids()\n",
    "for deployment_id in model_deployment_ids:\n",
    "    deployment = wml_client.deployments.get_details(deployment_id)\n",
    "    model_id = deployment['entity']['deployable_asset']['guid']\n",
    "    if deployment['entity']['name'] == DEPLOYMENT_NAME:\n",
    "        print('Deleting deployment id', deployment_id)\n",
    "        wml_client.deployments.delete(deployment_id)\n",
    "        print('Deleting model id', model_id)\n",
    "        wml_client.repository.delete(model_id)\n",
    "wml_client.repository.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the metadata and save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "    wml_client.repository.ModelMetaNames.NAME: MODEL_NAME,\n",
    "    wml_client.repository.ModelMetaNames.EVALUATION_METHOD: \"binary\",\n",
    "    wml_client.repository.ModelMetaNames.EVALUATION_METRICS: [\n",
    "        {\n",
    "            \"name\": \"areaUnderROC\",\n",
    "            \"value\": 0.7,\n",
    "            \"threshold\": 0.7\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Name the columns\n",
    "cols=[\"Income\",\"AppliedOnline\",\"Residence\",\"Yrs_at_Current_Address\",\"Yrs_with_Current_Employer\",\\\n",
    "      \"Number_of_Cards\",\"Creditcard_Debt\",\"Loans\",\"Loan_Amount\",\"SalePrice\",\"Location\"]\n",
    "      \n",
    "saved_model = wml_client.repository.store_model(model=model, meta_props=metadata, \n",
    "                                            training_data=X_train, training_target=y_train, \n",
    "                                            feature_names=cols, label_column_names=[\"MortgageDefault\"] )\n",
    "saved_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the unique ID for the model so we can deploy it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uid = saved_model['metadata']['guid']\n",
    "model_uid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy the model as a web service with Watson Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Deploying model...\")\n",
    "\n",
    "deployment = wml_client.deployments.create(artifact_uid=model_uid, name=DEPLOYMENT_NAME, asynchronous=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_uid = wml_client.deployments.get_uid(deployment)\n",
    "\n",
    "print(\"Model id: {}\".format(model_uid))\n",
    "print(\"Deployment id: {}\".format(deployment_uid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenScale Mortgage Default Configuration\n",
    "\n",
    "This pportion of the notebook will configure OpenScale monitoring for the mortgage default model using the Python client, as opposed to the graphical user interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_ai_openscale import APIClient\n",
    "from ibm_ai_openscale.engines import *\n",
    "from ibm_ai_openscale.utils import *\n",
    "from ibm_ai_openscale.supporting_classes import PayloadRecord, Feature\n",
    "from ibm_ai_openscale.supporting_classes.enums import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the instance ID for Watson OpenScale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from ibm_ai_openscale.utils import get_instance_guid\n",
    "\n",
    "WOS_GUID = get_instance_guid(api_key=CLOUD_API_KEY)\n",
    "WOS_CREDENTIALS = {\n",
    "    \"instance_guid\": WOS_GUID,\n",
    "    \"apikey\": CLOUD_API_KEY,\n",
    "    \"url\": \"https://api.aiopenscale.cloud.ibm.com\"\n",
    "}\n",
    "\n",
    "if WOS_GUID is None:\n",
    "    print('Watson OpenScale GUID NOT FOUND')\n",
    "else:\n",
    "    print(WOS_GUID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Cloud API key and WOS instance ID to create a new OpenScale client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_client = APIClient(aios_credentials=WOS_CREDENTIALS)\n",
    "ai_client.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the OpenScale datamart. First check for an existing datamart. If none is found, create one using the DB_CREDENTIALS if provided. If no credentials were provided, use the free internal datamart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data_mart_details = ai_client.data_mart.get_details()\n",
    "    if 'internal_database' in data_mart_details and data_mart_details['internal_database']:\n",
    "        print('Using existing internal datamart')\n",
    "    else:\n",
    "        print('Using existing external datamart')\n",
    "except:\n",
    "    if DB_CREDENTIALS is None:\n",
    "        print('Setting up internal datamart')\n",
    "        ai_client.data_mart.setup(internal_db=True)\n",
    "    else:\n",
    "        print('Setting up external datamart')\n",
    "        try:\n",
    "            ai_client.data_mart.setup(db_credentials=DB_CREDENTIALS)\n",
    "        except:\n",
    "            print('Setup failed, trying Db2 setup')\n",
    "            ai_client.data_mart.setup(db_credentials=DB_CREDENTIALS, schema=DB_CREDENTIALS['username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mart_details = ai_client.data_mart.get_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bind the OpenScale datamart to the WML instance. If the binding already exists, this will generate an error message, but will not affect the remainder of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binding_uid = ai_client.data_mart.bindings.add('WML Binding', WatsonMachineLearningInstance(WML_CREDENTIALS))\n",
    "bindings_details = ai_client.data_mart.bindings.get_details()\n",
    "\n",
    "ai_client.data_mart.bindings.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(binding_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the scoring endpoint for the deployed model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_details = wml_client.deployments.get_details(deployment_uid)\n",
    "scoring_endpoint = deployment_details['entity']['scoring_url']\n",
    "\n",
    "print('Model UID:', model_uid)\n",
    "print('Scoring URL:', scoring_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all the subscribed models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscriptions_uids = ai_client.data_mart.subscriptions.get_uids()\n",
    "ai_client.data_mart.subscriptions.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The credentials below point to the training data for the model, in CSV format. OpenScale uses the training data to train the drift model, and generate distribution statistics for the explainability service and the fairness monitor. If you don't want to provide this information to OpenScale, it is possible to run a custom notebook to create this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_credentials = {\n",
    "    \"apikey\": \"yqcPbWZ0AQPHleHVerrR4Wx5e9pymBdMgydbEra5zCif\",\n",
    "    \"api_key\": \"yqcPbWZ0AQPHleHVerrR4Wx5e9pymBdMgydbEra5zCif\",\n",
    "    \"url\": \"https://s3.us.cloud-object-storage.appdomain.cloud\",\n",
    "    \"iam_url\": 'https://iam.bluemix.net/oidc/token',\n",
    "    \"cos_hmac_keys\": {\n",
    "        \"access_key_id\": \"2d1be760f19241d695a534960da6eb80\",\n",
    "        \"secret_access_key\": \"e1252b952f47a6b3f42305b8ffe6f9bd7d10e45f966b9a62\"\n",
    "    },\n",
    "    \"endpoints\": \"https://control.cloud-object-storage.cloud.ibm.com/v2/endpoints\",\n",
    "    \"iam_apikey_description\": \"Auto-generated for key 2d1be760-f192-41d6-95a5-34960da6eb80\",\n",
    "    \"iam_apikey_name\": \"FastStartLab\",\n",
    "    \"iam_role_crn\": \"crn:v1:bluemix:public:iam::::serviceRole:Reader\",\n",
    "    \"iam_serviceid_crn\": \"crn:v1:bluemix:public:iam-identity::a/7d8b3c34272c0980d973d3e40be9e9d2::serviceid:ServiceId-568ba191-a3bf-48f2-a30c-f3a4af7ec61d\",\n",
    "    \"resource_instance_id\": \"crn:v1:bluemix:public:cloud-object-storage:global:a/7d8b3c34272c0980d973d3e40be9e9d2:2883ef10-23f1-4592-8582-2f2ef4973639::\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_reference = {\n",
    "    'type': 'cos',\n",
    "    'location': {\n",
    "        'bucket': 'faststartlab-donotdelete-pr-nhfd4jnhlxgpc7',\n",
    "        'file_name': 'Mortgage_Full_Records.csv',\n",
    "        'firstlineheader': True,\n",
    "        'file_format': 'csv'\n",
    "    },\n",
    "    'connection': cos_credentials,\n",
    "    'name': 'training data reference'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the subscription in OpenScale so we can monitor the model. Required information includes feature columns, categorical columns, problem types, input types, and output types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription = ai_client.data_mart.subscriptions.add(WatsonMachineLearningAsset(\n",
    "    model_uid,\n",
    "    problem_type=ProblemType.BINARY_CLASSIFICATION,\n",
    "    input_data_type=InputDataType.STRUCTURED,\n",
    "    label_column='MortgageDefault',\n",
    "    prediction_column='prediction',\n",
    "    probability_column='probability',\n",
    "    transaction_id_column='ID',\n",
    "    feature_columns = ['AppliedOnline','Residence','Location','Income','Yrs_at_Current_Address','Yrs_with_Current_Employer',\\\n",
    "                   'Number_of_Cards','Creditcard_Debt','Loan_Amount','Loans','SalePrice'],\n",
    "    categorical_columns = ['AppliedOnline','Residence','Location'],\n",
    "    training_data_reference = training_data_reference\n",
    "))\n",
    "\n",
    "if subscription is None:\n",
    "    print('Subscription already exists; get the existing one')\n",
    "    subscriptions_uids = ai_client.data_mart.subscriptions.get_uids()\n",
    "    for sub in subscriptions_uids:\n",
    "        if ai_client.data_mart.subscriptions.get_details(sub)['entity']['asset']['name'] == MODEL_NAME:\n",
    "            subscription = ai_client.data_mart.subscriptions.get(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscriptions_uids = ai_client.data_mart.subscriptions.get_uids()\n",
    "ai_client.data_mart.subscriptions.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_details = subscription.get_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score the model so we can begin configuring OpenScale monitors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm mortgage_feed.json\n",
    "!wget https://raw.githubusercontent.com/emartensibm/openscale-demos/master/mortgage-default/data/mortgage_feed.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('mortgage_feed.json', 'r') as scoring_file:\n",
    "    data = json.load(scoring_file)\n",
    "\n",
    "scoring_payload = {\n",
    "    \"fields\": data['fields'][1:],\n",
    "    \"values\": [],\n",
    "    \"meta\":{\n",
    "        \"fields\": [\"ID\"],\n",
    "        \"values\": []\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "letters = string.digits\n",
    "\n",
    "for _ in range(0, 201):\n",
    "    value_to_score = random.choice(data['values'])\n",
    "    scoring_payload['values'].append(value_to_score[1:])\n",
    "    scoring_payload['meta']['values'].append([int(''.join(random.choices(letters, k=8)))])\n",
    "print(len(scoring_payload['values']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = wml_client.deployments.score(scoring_endpoint, scoring_payload)\n",
    "print(predictions['values'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pause for ten seconds to give OpenScale time to create the datamart schema, then show the number of records in the datamart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10)\n",
    "subscription.payload_logging.get_records_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enable quality monitoring. Set the alert threshold at 70%, and the minimum records for scoring at 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription.quality_monitoring.enable(threshold=0.7, min_records=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enable fairness monitoring. In this case, we'll monitor online applications, since they are under-represented in our training data. The fairness alert threshold will be set at 90%, and we will require at least 200 records for scoring. Note that we have to supply a favourable and unfavourable model outcome, as well as a majority (reference) and minority (monitored) group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription.fairness_monitoring.enable(\n",
    "    features=[\n",
    "        Feature(\"AppliedOnline\", majority=['NO'], minority=['YES'], threshold=0.90)\n",
    "    ],\n",
    "    favourable_classes=['NO'],\n",
    "    unfavourable_classes=['YES'],\n",
    "    min_records=200\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure drift monitoring. Set the alert threshold at 5% predicted drop in accuracy, and the minimum records required for scoring at 100. This will begin training the drift monitor model in OpenScale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription.drift_monitoring.enable(threshold=0.05, min_records=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monitor the creation of the drift monitor. Check every 30 seconds to see if it has been successfully created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drift_status = None\n",
    "while drift_status != 'finished':\n",
    "    drift_details = subscription.drift_monitoring.get_details()\n",
    "    drift_status = drift_details['parameters']['config_status']['state']\n",
    "    if drift_status != 'finished':\n",
    "        print(drift_status)\n",
    "        time.sleep(30)\n",
    "print(drift_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(drift_details['parameters'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually run the fairness monitor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness_run_details = subscription.fairness_monitoring.run(background_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness_run_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription.fairness_monitoring.show_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually run the drift monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drift_run_details = subscription.drift_monitoring.run(background_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drift_run_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription.drift_monitoring.show_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload feedback data to run the quality monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_payload_set = df.values.tolist()\n",
    "\n",
    "feedback_payload = []\n",
    "for _ in range(0, 101):\n",
    "    feedback_payload.append(random.choice(feedback_payload_set))\n",
    "print(feedback_payload[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription.feedback_logging.store(feedback_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10)\n",
    "subscription.feedback_logging.show_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_details = subscription.quality_monitoring.run(background_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10)\n",
    "subscription.quality_monitoring.show_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enable explainability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_ai_openscale.supporting_classes import *\n",
    "\n",
    "subscription.explainability.enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a transaction to explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_id = subscription.payload_logging.get_table_content(limit=1)['scoring_id'].values[0]\n",
    "\n",
    "print(transaction_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_run = subscription.explainability.run(transaction_id=transaction_id, background_mode=False, cem=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations!\n",
    "\n",
    "You have successfully created the mortgage default model and configured it for monitoring with Watson OpenScale. Next, set up the model feed notebook to run at regular intervals to pump data into your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
